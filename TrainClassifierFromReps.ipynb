{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fccef15f-f077-4bcc-bb90-7fbefa33c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_info import BigDecoder, BigMultiHeadClassifier\n",
    "from models import get_model_from_exp\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "import argparse\n",
    "from utils import get_args\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_batch(model, batch, optimizer, device):\n",
    "    model.train()\n",
    "    if len(batch) == 3:\n",
    "        x, _,  y = batch  # x: images, y: tuple of 6 tensors (B,)\n",
    "    else:\n",
    "        x, y = batch\n",
    "    x = x.float().to(device)\n",
    "    y = [y[:, i].to(device) for i in range(y.shape[1])]\n",
    "    outputs = model(x)  # list of logits per head\n",
    "\n",
    "    # Calculate losses and accuracies per head\n",
    "    losses = [F.cross_entropy(logits, targets) for logits, targets in zip(outputs, y)]\n",
    "    preds = [torch.argmax(logits, dim=1) for logits in outputs]\n",
    "    accuracies = [(pred == target).float().mean().item() for pred, target in zip(preds, y)]\n",
    "\n",
    "    # Total loss is the sum\n",
    "    loss = sum(losses)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss.item(),\n",
    "        \"head_losses\": [l.item() for l in losses],\n",
    "        \"head_accuracies\": accuracies,\n",
    "        \"overall_accuracy\": sum(accuracies) / len(accuracies)\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "\n",
    "        # Tracking variables\n",
    "        running_loss = 0.0\n",
    "        running_accuracies = [0.0] * len(model.output_dims)\n",
    "        total_batches = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            metrics = train_batch(model, batch, optimizer, device)\n",
    "\n",
    "            running_loss += metrics[\"loss\"]\n",
    "            for i, acc in enumerate(metrics[\"head_accuracies\"]):\n",
    "                running_accuracies[i] += acc\n",
    "            total_batches += 1\n",
    "        # Average training metrics\n",
    "        avg_loss = running_loss / total_batches\n",
    "        avg_head_accuracies = [acc / total_batches for acc in running_accuracies]\n",
    "        avg_overall_accuracy = sum(avg_head_accuracies) / len(avg_head_accuracies)\n",
    "\n",
    "        print(f\"Train Loss: {avg_loss:.4f} | Avg Accuracy per Head: {[f'{a:.3f}' for a in avg_head_accuracies]} | Overall: {avg_overall_accuracy:.3f}\")\n",
    "\n",
    "def get_reps_from_model(exp_id):\n",
    "    \n",
    "    args = get_args(exp_id,update_id=True)\n",
    "    args.encoder['pretrain_method'] = None\n",
    "    model = get_model_from_exp(args)\n",
    "    # Data loader is simply a TensorDataset of \n",
    "    dl = get_dataloader(args)\n",
    "    # create reps for full dataset for training autoencoder\n",
    "    reps = get_reps(args, model, dl)\n",
    "    return reps\n",
    "\n",
    "def get_reps(args, model, dl):\n",
    "    reps = []\n",
    "    with torch.no_grad():\n",
    "        for img, rep, latents in tqdm(dl):\n",
    "            bs = rep.shape[0]\n",
    "            rep = rep.float().cuda()\n",
    "\n",
    "            delta = torch.zeros(bs, len(args.FOVS_PER_DATASET)).cuda()\n",
    "            new_rep = model.modulator(rep, delta)\n",
    "            reps.append(new_rep.cpu())\n",
    "        return torch.cat(reps, dim=0)\n",
    "\n",
    "def get_dataloader(args, indices = [], bs=1024, shuffle=False):\n",
    "    \n",
    "    data = torch.load(f\"{args.dataset}/{args.dataset}.pth\", map_location=\"cpu\")\n",
    "    reps_path = None\n",
    "    if args.pretrained_reps:\n",
    "        reps_path = args.pretrained_reps\n",
    "    elif args.pretrained_encoder:\n",
    "        encoder_args = get_args(args.pretrained_encoder)\n",
    "        reps_path = encoder_args.pretrained_reps\n",
    "    have_reps = reps_path is not None\n",
    "    if have_reps:\n",
    "        print(\"using pretrained reps...\")\n",
    "        data['reps'] = torch.load(f\"{args.dataset}/{args.dataset}_images_feats_{reps_path}.pth\", map_location=\"cpu\") if reps_path else None\n",
    "        data['reps'] = data['reps'] - data['reps'].mean(dim=0) # center\n",
    "        data['reps'] = torch.nn.functional.normalize(data['reps'], p=2.0, dim=1, eps=1e-12)\n",
    "    else:\n",
    "        print(\"using input images\")\n",
    "    if indices == []:\n",
    "        indices = torch.tensor([i for i in range(data['images'].shape[0])])\n",
    "    ds = TensorDataset(\n",
    "                data['images'][indices]/255.0,\n",
    "                data['reps'][indices] if have_reps else data['latents'][indices],\n",
    "                data['latent_ids'][indices]\n",
    "                )\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=bs, shuffle=shuffle)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ff8e3-0f07-4319-86de-87a525b66f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating reps from pretrained model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exp_id = \"e99wn9i9\"\n",
    "args = get_args(exp_id, update_id=True)\n",
    "print(\"Generating reps from pretrained model...\")\n",
    "reps = get_reps_from_model(args.experiment_id)\n",
    "latents =  torch.load(f\"{args.dataset}/{args.dataset}.pth\")['latent_ids']\n",
    "print(\"Training from reps\")\n",
    "ds = TensorDataset(reps, latents)\n",
    "dl = DataLoader(ds, batch_size=256, shuffle=True)\n",
    "\n",
    "model = BigMultiHeadClassifier(d_hidden=128, use_encoder=False,num_blocks=4)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "device = \"cuda\"\n",
    "\n",
    "train_model(model, dl, optimizer, device, num_epochs=20 if parsed_args.from_imgs else 100)\n",
    "\n",
    "filename = f\"{parsed_args.exp_id}_classifier_reps.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), f\"results/classifiers/{args.dataset}/{filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805824ec-ec0a-4145-b229-33b5367ff1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
