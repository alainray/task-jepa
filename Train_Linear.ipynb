{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a606d83a-f7d3-4eaf-91fd-ac20ccc2dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araymond/storage/pyenv/versions/3.10.14/envs/mini/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "There was a problem when trying to write in your cache folder (/storage/cache). You should set the environment variable TRANSFORMERS_CACHE to a writable directory.\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from easydict import EasyDict as edict\n",
    "from datasets import get_dataloaders\n",
    "args = edict()\n",
    "args.dataset = \"3dshapes\"\n",
    "args.sub_dataset = \"composition\"\n",
    "args.make_random_batches = True\n",
    "args.train_method = \"linear\"\n",
    "args.pretrained_reps = False\n",
    "args.pretrained_encoder = False\n",
    "args.encoder = edict()\n",
    "args.encoder.arch = \"cnn\"\n",
    "args.train_bs = 256\n",
    "args.num_workers=0\n",
    "args.accum_batches = 1\n",
    "args.num_steps = 100000\n",
    "args.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f0a959f-bfc0-4a02-a296-93cf55d0783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from model_info import BigEncoder\n",
    "\n",
    "class LightningLinear(L.LightningModule):\n",
    "    def __init__(self, args, encoder, hidden_dim=128, latent_dim=5, **kwargs):\n",
    "        super().__init__()        \n",
    "        self.args = args\n",
    "        self.encoder = encoder\n",
    "        self.directions = nn.Parameter(torch.randn(latent_dim, hidden_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(1,hidden_dim))\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def modulate(self, x, delta=None):\n",
    "        if delta is None:\n",
    "            bs = x.shape[0]\n",
    "            device = x.device\n",
    "            delta = torch.zeros((bs,self.latent_dim),device=device)\n",
    "        delta_dirs = delta.unsqueeze(-1)*self.directions\n",
    "\n",
    "        return x + delta_dirs\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        return x\n",
    "\n",
    "    def linear_model_loss(self, reps, latents):\n",
    "        bias = self.bias\n",
    "        dirs = self.directions\n",
    "        delta_dirs =  latents.unsqueeze(-1)*dirs\n",
    "        reconstructed_reps = bias + delta_dirs.sum(dim=1)\n",
    "        loss = ((reps - (reconstructed_reps))**2).mean() \n",
    "        return loss\n",
    "\n",
    "    def log_metrics_split(self, metrics, split):\n",
    "        metrics = {f'{split}_{k}': v for k,v in metrics.items()}\n",
    "        self.log_dict({k: v.item() for k, v in metrics.items()}, on_step=True, on_epoch=True, prog_bar=True, add_dataloader_idx=False)\n",
    "        return metrics # so lightning can train\n",
    "    \n",
    "    def step(self, batch):\n",
    "        imgs, _, latents = batch\n",
    "        metrics = dict()\n",
    "        reps = self.encode(imgs.float())\n",
    "        loss = self.linear_model_loss(reps, latents.float())\n",
    "        metrics = {'loss': loss, 'linear_loss': loss}\n",
    "        return metrics \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        split = \"train\"\n",
    "        metrics = self.step(batch)\n",
    "        metrics = self.log_metrics_split(metrics, split)\n",
    "        return metrics[f'{split}_loss']\n",
    "      \n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        split = \"val\"\n",
    "        metrics = self.step(batch)\n",
    "        metrics = self.log_metrics_split(metrics, split)\n",
    "        return metrics[f'{split}_loss']\n",
    "        \n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        split = \"test\"\n",
    "        metrics = self.step(batch)\n",
    "        metrics = self.log_metrics_split(metrics, split)\n",
    "        return metrics[f'{split}_loss']\n",
    "    \n",
    "    def configure_optimizers(self):        \n",
    "        params = []\n",
    "\n",
    "        if hasattr(self, 'encoder') and self.encoder is not None:\n",
    "            params += list(self.encoder.parameters())\n",
    "        if hasattr(self, 'modulator') and self.modulator is not None:\n",
    "            params += list(self.modulator.parameters())\n",
    "        if hasattr(self, 'regressor') and self.regressor is not None:\n",
    "            params += list(self.regressor.parameters())\n",
    "        if hasattr(self, 'decoder') and self.decoder is not None:\n",
    "            params += list(self.decoder.parameters())\n",
    "        \n",
    "        param_groups = [{'params': params}]\n",
    "\n",
    "        return torch.optim.AdamW(param_groups, lr=self.args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44238ae7-f902-4681-bc53-5f58b71932e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model!\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating model!\", flush=True)\n",
    "encoder = BigEncoder(args)\n",
    "model = LightningLinear(args, encoder=encoder, hidden_dim=256, latent_dim=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a4db54-316a-4ec2-b2f4-047fcb3c048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataloaders...\n",
      "Loading 3dshapes dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataloaders...\", flush=True)\n",
    "dls = get_dataloaders(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84d837bd-7652-4492-9dca-cd713fd8ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | encoder      | BigEncoder | 381 K \n",
      "  | other params | n/a        | 1.8 K \n",
      "--------------------------------------------\n",
      "383 K     Trainable params\n",
      "0         Non-trainable params\n",
      "383 K     Total params\n",
      "1.532     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac5a4bc2e2744a183033f45cb224c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100000` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(accelerator=\"gpu\",\n",
    "                    devices=1,\n",
    "                    enable_progress_bar=True,\n",
    "                    accumulate_grad_batches=args.accum_batches,\n",
    "                    check_val_every_n_epoch=None,\n",
    "                    max_steps=args.num_steps,\n",
    "                    val_check_interval=10000,\n",
    "                    callbacks=[],\n",
    "                    logger=[])\n",
    "trainer.fit(model=model,\n",
    "            train_dataloaders=dls['train'],\n",
    "            val_dataloaders=[dls['val']],\n",
    "            ckpt_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec73a080-6335-43e9-89cc-18d61e5c829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dls['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18657e91-d35c-4103-be1f-434ec8d9d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _, latents = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b7fa55d-2db6-4f80-abb2-5667459ea84a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)) \n\u001b[1;32m      2\u001b[0m b\u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m (\u001b[43ma\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mb\u001b[49m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.randn((256, 256)) \n",
    "b=  torch.randn(256, 6, 256)\n",
    "(a+b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11815112-d0ed-4392-afa4-f29d068247a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1766e90-d29e-473f-a493-8ff9e9089cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11.7509,   1.6815,  -4.6021,  ...,  -4.8339,  16.6794,   5.3639],\n",
       "        [-16.7556,  -4.9350, -12.2518,  ...,   3.1550,  26.3667,  -3.7114],\n",
       "        [ -6.3644,  -8.6171,  -2.7505,  ...,   1.7719,   0.4567,  -0.4432],\n",
       "        ...,\n",
       "        [ -4.6241,  -9.5187,  -8.6548,  ...,   0.8589,  -5.1543,   7.2975],\n",
       "        [ -9.8387,  -1.2096, -11.7213,  ...,   1.3912,  17.7150,   0.0394],\n",
       "        [-12.0111,  -4.0808,   0.1939,  ...,  -2.1665,  14.3975,   0.3059]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(imgs.float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f0513-1cb7-4687-81b9-551ad75d8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_info import LinearModulator\n",
    "\n",
    "m = LinearModulator( input_dim=256, hidden_dim=256, latent_dim=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20dc3a-11e0-40ba-89ff-23617092049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data=torch.randn(10, 256)\n",
    "\n",
    "m(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2305c4-181a-41fa-b1ce-886a4a691f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
